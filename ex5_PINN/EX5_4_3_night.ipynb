{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2620536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch 0: Loss = 5.138609, Slope ≈ -0.000949\n",
      "Epoch 100: Loss = 1.606199, Slope ≈ -0.963946\n",
      "Epoch 200: Loss = 0.539728, Slope ≈ -2.564134\n"
     ]
    }
   ],
   "source": [
    "# Physics-Informed Neural Network for Periodic Advection Equation (Exercise 3)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use double precision for better accuracy\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "# Select device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Neural network model\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PINN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 30),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(30, 30),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(30, 30),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(30, 30),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(30, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        xt = torch.cat((x, t), dim=1)\n",
    "        return self.net(xt)\n",
    "\n",
    "# Gradient function for autograd\n",
    "def grad(outputs, inputs):\n",
    "    return torch.autograd.grad(outputs, inputs, grad_outputs=torch.ones_like(outputs), create_graph=True)[0]\n",
    "\n",
    "# Loss function for periodic advection problem\n",
    "def loss_fn(model, x, t, eps):\n",
    "    x.requires_grad_(True)\n",
    "    t.requires_grad_(True)\n",
    "    u = model(x, t)\n",
    "    u_t = grad(u, t)\n",
    "    u_x = grad(u, x)\n",
    "    u_xx = grad(u_x, x)\n",
    "    u_squared = u * u\n",
    "    u_squared_x = grad(u_squared, x)\n",
    "\n",
    "    # PDE residual\n",
    "    f = u_t + 0.5 * u_squared_x - eps * u_xx\n",
    "\n",
    "    # Define t values for BCs\n",
    "    t_bc = torch.linspace(tmin, tmax, 200, device=device).unsqueeze(1)\n",
    "\n",
    "    # Homogeneous boundary conditions: u(-1, t) = u(1, t) = 0\n",
    "    bcL = model(torch.full_like(t_bc, -1), t_bc)\n",
    "    bcR = model(torch.full_like(t_bc, 1), t_bc)\n",
    "\n",
    "    # Initial condition: u(x, 0) = -sin(pi*x)\n",
    "    ic = model(x, torch.zeros_like(t)) + torch.sin(np.pi * x)\n",
    "\n",
    "    # Compute losses\n",
    "    loss_pde = torch.mean(f**2)\n",
    "    loss_bc = torch.mean(bcL**2 + bcR**2)\n",
    "    loss_ic = torch.mean(ic**2)\n",
    "\n",
    "    return loss_pde + 10.0 * loss_bc + 10.0 * loss_ic\n",
    "\n",
    "# Domain settings\n",
    "eps = 0.01/np.pi  # Diffusion coefficient\n",
    "xmin, xmax, nx = -1, 1, 200\n",
    "tmin, tmax, nt = 0, 1.6037/np.pi, 200\n",
    "\n",
    "x = torch.linspace(xmin, xmax, nx, device=device).unsqueeze(1)\n",
    "t = torch.linspace(tmin, tmax, nt, device=device).unsqueeze(1)\n",
    "x_mesh, t_mesh = torch.meshgrid(x.flatten(), t.flatten(), indexing='ij')\n",
    "x_mesh = x_mesh.reshape(-1, 1)\n",
    "t_mesh = t_mesh.reshape(-1, 1)\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = PINN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training function with logging\n",
    "def train(model, epochs, optimizer, x, t, eps):\n",
    "    loss_log = []\n",
    "    slope_log = []\n",
    "    epoch_log = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(model, x, t, eps)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            x0 = torch.tensor([[0.0]], device=device, requires_grad=True)\n",
    "            t_final = torch.tensor([[tmax]], device=device)\n",
    "            u = model(x0, t_final)\n",
    "            slope = torch.autograd.grad(u, x0, grad_outputs=torch.ones_like(u), create_graph=False)[0].item()\n",
    "\n",
    "\n",
    "            loss_val = loss.item()\n",
    "            loss_log.append(loss_val)\n",
    "            slope_log.append(slope)\n",
    "            epoch_log.append(epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch}: Loss = {loss_val:.6f}, Slope ≈ {slope:.6f}\")\n",
    "\n",
    "    # Save logs\n",
    "    np.save(\"log_epochs.npy\", np.array(epoch_log))\n",
    "    np.save(\"log_losses.npy\", np.array(loss_log))\n",
    "    np.save(\"log_slopes.npy\", np.array(slope_log))\n",
    "    torch.save(model.state_dict(), \"pinn_burgers_model.pt\")\n",
    "\n",
    "# Train the model\n",
    "train(model, 15000, optimizer, x_mesh, t_mesh, eps)\n",
    "\n",
    "# Prediction and visualization\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    u_pred = model(x_mesh, t_mesh).cpu().numpy()\n",
    "\n",
    "x_cpu = x.cpu().numpy().flatten()\n",
    "t_cpu = t.cpu().numpy().flatten()\n",
    "x_edges = np.append(x_cpu, x_cpu[-1] + (x_cpu[1] - x_cpu[0])) - (x_cpu[1] - x_cpu[0]) / 2\n",
    "t_edges = np.append(t_cpu, t_cpu[-1] + (t_cpu[1] - t_cpu[0])) - (t_cpu[1] - t_cpu[0]) / 2\n",
    "\n",
    "# Prepare spatial grid x for t=0 and t=tmax\n",
    "x_plot = torch.linspace(xmin, xmax, nx, device=device).unsqueeze(1)\n",
    "\n",
    "# Time tensors\n",
    "t0 = torch.zeros_like(x_plot)\n",
    "t_end = torch.full_like(x_plot, tmax)\n",
    "\n",
    "# Predict at t=0 and t=tmax\n",
    "with torch.no_grad():\n",
    "    u_t0 = model(x_plot, t0).cpu().numpy()\n",
    "    u_tend = model(x_plot, t_end).cpu().numpy()\n",
    "\n",
    "# Exact solutions (placeholder if needed)\n",
    "x_np = x_plot.cpu().numpy()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x_np, u_t0, '-', label='PINN t=0')\n",
    "plt.title(\"Solution at t = 0\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"u\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x_np, u_tend, '-', label=f'PINN t={tmax:.4f}')\n",
    "plt.title(f\"Solution at t = {tmax:.4f}\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"pinn_results.png\")\n",
    "plt.show()\n",
    "\n",
    "# Evaluate slope at center\n",
    "x0 = torch.tensor([[0.0]], device=device, requires_grad=True)\n",
    "t_final = torch.tensor([[tmax]], device=device)\n",
    "u = model(x0, t_final)\n",
    "u_x = torch.autograd.grad(u, x0, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "\n",
    "with open(\"slope_at_center.txt\", \"w\") as f:\n",
    "    f.write(f\"∂u/∂x at x=0, t={tmax:.4f} ≈ {u_x.item():.6f}\\n\")\n",
    "\n",
    "print(f\"∂u/∂x at x=0, t={tmax:.4f} ≈ {u_x.item():.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sciml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
